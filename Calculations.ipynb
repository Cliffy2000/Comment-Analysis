{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import math\n",
    "import json\n",
    "import gzip\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from tqdm.notebook import trange, tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Single String Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "words1 = [\n",
    "    'lorem', 'ipsum', 'dolor', 'sit', 'amet', 'consectetur', 'adipiscing', 'elit', 'pellentesque', 'sodales', \n",
    "    'turpis', 'eu', 'fermentum', 'luctus', 'arcu', 'velit', 'pulvinar', 'est', 'eu', 'pellentesque'\n",
    "    ]\n",
    "words2 = [\n",
    "    'cats', 'cats', 'cats', 'cats', 'cats', 'cats', 'cats', 'cats', 'cats', 'cats', \n",
    "    'banana', 'banana', 'banana', 'banana', 'banana', 'banana', 'banana', 'banana', 'banana', 'banana'\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entropy\n",
    "\n",
    "def calculateEntropy(words):\n",
    "    wordFrequencies = Counter(words)\n",
    "    total = len(words)\n",
    "\n",
    "    entropy = -sum((freq / total) * math.log2(freq / total) for freq in wordFrequencies.values())\n",
    "    return entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.1219280948873624\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "print(calculateEntropy(words1))\n",
    "print(calculateEntropy(words2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compression Ratio\n",
    "\n",
    "def calculateCompressionRatio(words):\n",
    "    original = ''.join(words).encode('utf-8')\n",
    "    originalSize = len(original)\n",
    "\n",
    "    buffer = io.BytesIO()\n",
    "    with gzip.GzipFile(fileobj=buffer, mode=\"wb\") as f:\n",
    "        f.write(original)\n",
    "    \n",
    "    compressed = buffer.getvalue()\n",
    "    compressedSize = len(compressed)\n",
    "    \n",
    "    return originalSize / compressedSize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1826923076923077\n",
      "3.0303030303030303\n"
     ]
    }
   ],
   "source": [
    "print(calculateCompressionRatio(words1))\n",
    "print(calculateCompressionRatio(words2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Most Repeated Substring\n",
    "# This function looks for the most repeated substring in a string/sentence. A very inefficient function. \n",
    "\n",
    "def findMostRepeated(words):\n",
    "    string = ''.join(words).replace('\\n', '')\n",
    "\n",
    "    if len(string) < 3:\n",
    "        return 1, ''\n",
    "\n",
    "    checked = set()\n",
    "    maxRepetition = 0\n",
    "    maxSubstring = ''\n",
    "    \n",
    "    for i in range(len(string)-1):\n",
    "        for j in range(i+2, len(string)+1):\n",
    "            substring = string[i:j]\n",
    "\n",
    "            if substring not in checked:\n",
    "                frequency = (len(string.split(substring)) - 1)\n",
    "                score = (len(string.split(substring)) - 1) * len(substring)\n",
    "                if score > maxRepetition and frequency > 1:\n",
    "                    maxRepetition = score\n",
    "                    maxSubstring = substring\n",
    "                checked.add(substring)\n",
    "    \n",
    "    return maxRepetition, maxSubstring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22, 'ellentesque')\n",
      "(60, 'banana')\n"
     ]
    }
   ],
   "source": [
    "print(findMostRepeated(words1))\n",
    "print(findMostRepeated(words2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test unit\n",
    "\n",
    "with open(\"DataFile1.json\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "\n",
    "for i in tqdm(range(len(df['content']))):\n",
    "    scores.append(findMostRepeated(df['content'][i])[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "String Pair Similarity Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize(sentence: list, uniqueWords: set):\n",
    "    frequency = dict.fromkeys(uniqueWords, 0)\n",
    "    frequency.update(Counter(sentence))\n",
    "    return frequency.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cosine Similarity\n",
    "\n",
    "def calculateCosine(sentence1: list, sentence2: list):\n",
    "    allWords = set(sentence1 + sentence2)\n",
    "    vector1 = vectorize(sentence1, allWords)\n",
    "    vector2 = vectorize(sentence2, allWords)\n",
    "\n",
    "    dot = sum(x * y for x,y in zip(vector1, vector2))\n",
    "    mag1 = sum(x ** 2 for x in vector1) ** 0.5\n",
    "    mag2 = sum(x ** 2 for x in vector2) ** 0.5\n",
    "\n",
    "    return dot / (mag1 * mag2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculateCosine(words1, words2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jaccard Similarity\n",
    "\n",
    "def calculateJaccard(sentence1: list, sentence2: list):\n",
    "    allWords = set(sentence1 + sentence2)\n",
    "    vector1 = vectorize(sentence1, allWords)\n",
    "    vector2 = vectorize(sentence2, allWords)\n",
    "\n",
    "    intersection = sum(min(x,y) for x,y in zip(vector1, vector2))\n",
    "    bagSum = sum((x + y - min(x,y)) for x,y in zip(vector1, vector2))\n",
    "\n",
    "    if bagSum == 0: \n",
    "        return 0\n",
    "    return intersection / bagSum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculateJaccard(words1, words2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Edit distances such as Levenshtein distance and longest common substring all involve dynamic programming, thus are not considered"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cluster Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
